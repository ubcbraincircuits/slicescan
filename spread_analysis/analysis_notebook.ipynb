{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b91b819-fa4a-4597-8be1-ea6003b41c22",
   "metadata": {},
   "source": [
    "# Slice experiments - Spread Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2840e-1eba-47b6-9917-6ed9b914579a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook contains code to analyze fluorescence signals recorded during slice experiments, specifically used for two different types of experiments: **iGluSnFR** and **dLight** imaging. These experiments are designed to measure glutamate and dopamine release, respectively, using genetically encoded sensors. The fluorescence signal recorded from these sensors is processed to calculate $\\Delta F/F$ (delta F over F; dff), and activation areas are determined based on the fluorescence response to various stimuli or drug treatments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38be54-f659-4d40-a203-a32e2f3eaabe",
   "metadata": {},
   "source": [
    "### Data Structure Overview\n",
    "\n",
    "The data in these experiments is organized into two distinct structures based on the type of experiment:\n",
    "1. **Quinpirole Drug Treatment Experiments:**\n",
    "\n",
    "In this set of experiments, the fluorescence signal was recorded during different phases of a drug treatment protocol involving Quinpirole, a dopamine receptor agonist. The data is structured in folders representing different phases of the experiment:\n",
    "\n",
    "- *Baseline*: The initial condition before drug treatment.\n",
    "- *Treatment*: The phase during which the drug (Quinpirole) was applied.\n",
    "- *Wash*: The recovery phase after the drug was washed out.\n",
    "\n",
    "Each of these folders contains multiple TIFF stacks representing the fluorescence signal from various sweeps. These TIFF files are labeled as:\n",
    "\n",
    "- `hiX.tif`: High-intensity fluorescence recordings.\n",
    "- `loX.tif`: Low-intensity fluorescence recordings (optional, not present in some experiments. Refer to the methods of the paper).\n",
    "- `noX.tif`: Control or baseline fluorescence.\n",
    "\n",
    "$X$ represents the sweep number. The dF/F is calculated by comparing the high and low signals to the baseline, and the activation area is determined based on a threshold derived from the fluorescence variability. The threshold is set to $ 4 \\times STD(Frames[:30])$\n",
    "\n",
    "\n",
    "2. **Stimulus-Response (Stim-Response) Experiments:**\n",
    "\n",
    "In these experiments, the slices were electrically stimulated, and the fluorescence response to the stimulation was measured. The data is organized in folders representing different stimulus intensities, labeled by their current (in microamperes, uA). Each folder contains fluorescence recordings for a specific stimulation intensity:\n",
    "\n",
    "different current intensities used in the experiment:    `50uA`, `60uA`, `70uA`, `80uA`, `100uA`, `200uA`, `300uA`, `400uA`, `500uA`\n",
    "\n",
    "Each uA folder contains multiple TIFF stacks labeled similarly to the drug treatment experiments:\n",
    "\n",
    "- `hiX.tif`: High-intensity fluorescence recordings.\n",
    "- `loX.tif`: Low-intensity fluorescence recordings.\n",
    "- `noX.tif`: Control or baseline fluorescence.\n",
    "\n",
    "$X$ represents the sweep number. The dF/F is calculated by averaging the responses across all the sweeps in each folder, and the activation area is calculated based on the same thresholding method.\n",
    "Purpose of the Analysis\n",
    "\n",
    "The primary goal of this analysis is to calculate and visualize the dF/F signal across the experimental conditions and determine the activation areas based on the fluorescence response. The code processes both Quinpirole drug treatment experiments and stim-response experiments, calculates the dF/F for each set of TIFF stacks, and generates 3D plots to visualize the average fluorescence response. Additionally, the activation areas for each set of conditions are saved in an Excel sheet for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e26412-91c6-4e26-a825-18059ebb2865",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Analysis of Quinpirole Experiments\n",
    "\n",
    "This section is for analyzing the activated area over time following stimulation (Activation Volume). The output is an excel spreadsheet, with each column representing an experiment, and each row a sweep. The cells are color coded:\n",
    "- No Fill: for the baseline sweeps\n",
    "- Green: for Quin drug treatment\n",
    "- Grey: for final aCSF wash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e4827de-5893-44d0-a226-18ca36e1df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "\n",
    "# Helper function for natural sorting of file names\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "\n",
    "def process_directory(root_folder):\n",
    "    # Create a master dictionary to store the final results\n",
    "    master_data = {}\n",
    "\n",
    "    # Go through each folder (root directories containing 'Baseline *', 'Treatment *', 'Wash *')\n",
    "    for folder in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        sub_dirs = ['Baseline', 'Treatment', 'Wash']\n",
    "        sweep_data = []\n",
    "\n",
    "        # Process each subdirectory (Baseline, Treatment, Wash)\n",
    "        for sub_dir in sub_dirs:\n",
    "            # Find the subdirectory that starts with 'Baseline', 'Treatment', or 'Wash'\n",
    "            matching_sub_dirs = [d for d in os.listdir(folder_path) if d.startswith(sub_dir)]\n",
    "            if not matching_sub_dirs:\n",
    "                continue\n",
    "\n",
    "            # There should be only one matching subdirectory, use it\n",
    "            sub_dir_path = os.path.join(folder_path, matching_sub_dirs[0])\n",
    "            print(sub_dir_path)\n",
    "            # Gather all the hi, lo, and no tiff files\n",
    "            hi_files = sorted([f for f in os.listdir(sub_dir_path) if f.startswith('hi') and f.endswith('.tif')], key=natural_sort_key)\n",
    "            lo_files = sorted([f for f in os.listdir(sub_dir_path) if f.startswith('lo') and f.endswith('.tif')], key=natural_sort_key)\n",
    "            no_files = sorted([f for f in os.listdir(sub_dir_path) if f.startswith('no') and f.endswith('.tif')], key=natural_sort_key)\n",
    "\n",
    "            for i, hi_file in enumerate(hi_files):\n",
    "                hi_stack = np.array(tiff.imread(os.path.join(sub_dir_path, hi_file)),dtype=np.float32)\n",
    "                no_stack = np.array(tiff.imread(os.path.join(sub_dir_path, no_files[i])),dtype=np.float32)\n",
    "\n",
    "                if i < len(lo_files):\n",
    "                    lo_stack = np.array(tiff.imread(os.path.join(sub_dir_path, lo_files[i])),dtype=np.float32)\n",
    "                    dff_stack = (hi_stack - no_stack) / no_stack + (lo_stack - no_stack) / no_stack\n",
    "                    dff_stack /= 2  # Averaging the two dff calculations\n",
    "                else:\n",
    "                    dff_stack = (hi_stack - no_stack) / no_stack\n",
    "\n",
    "                total_activation_area = calculate_activation_area(dff_stack)\n",
    "                sweep_data.append({\n",
    "                    'sweep': f'Sweep_{i+1}',\n",
    "                    'sub_dir': sub_dir,\n",
    "                    'activation_area': total_activation_area\n",
    "                })\n",
    "\n",
    "        # Add data to master dictionary with folder name as key\n",
    "        master_data[folder] = sweep_data\n",
    "\n",
    "    # Save the data into an Excel file with folder-based columns and color formatting\n",
    "    save_excel(master_data, os.path.join(root_folder, 'master_dff_results_colored.xlsx'))\n",
    "\n",
    "\n",
    "def calculate_activation_area(dff_stack):\n",
    "    # Calculate the threshold for each pixel based on the first 30 frames\n",
    "    std_dev = np.std(dff_stack[:30], axis=0)\n",
    "    threshold = 4 * std_dev\n",
    "\n",
    "    # Count how many pixels are above the threshold for each frame\n",
    "    activated_area = np.sum(dff_stack > threshold, axis=(1, 2))\n",
    "\n",
    "    # Total area activated across all frames\n",
    "    total_activation_area = np.sum(activated_area)\n",
    "    return total_activation_area\n",
    "\n",
    "\n",
    "def save_excel(master_data, output_path):\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"dFF Results\"\n",
    "\n",
    "    # Define the colors for each subdirectory\n",
    "    baseline_fill = PatternFill(start_color=\"FFFFFF\", end_color=\"FFFFFF\", fill_type=\"solid\")  # No Fill\n",
    "    treatment_fill = PatternFill(start_color=\"00FF00\", end_color=\"00FF00\", fill_type=\"solid\")  # Green\n",
    "    wash_fill = PatternFill(start_color=\"808080\", end_color=\"808080\", fill_type=\"solid\")  # Grey\n",
    "\n",
    "    # Write header\n",
    "    ws.append(['Sweep'] + list(master_data.keys()))\n",
    "\n",
    "    # Find maximum number of sweeps across all folders\n",
    "    max_sweeps = max([len(data) for data in master_data.values()])\n",
    "\n",
    "    # Fill the Excel file with data\n",
    "    for row_index in range(max_sweeps):\n",
    "        row_data = [f'Sweep_{row_index+1}']\n",
    "        for folder, sweeps in master_data.items():\n",
    "            if row_index < len(sweeps):\n",
    "                sweep_info = sweeps[row_index]\n",
    "                activation_area = sweep_info['activation_area']\n",
    "                sub_dir = sweep_info['sub_dir']\n",
    "\n",
    "                # Append activation area\n",
    "                row_data.append(activation_area)\n",
    "\n",
    "                # Apply the color based on the subdirectory\n",
    "                if sub_dir.startswith('Baseline'):\n",
    "                    fill = baseline_fill\n",
    "                elif sub_dir.startswith('Treatment'):\n",
    "                    fill = treatment_fill\n",
    "                else:\n",
    "                    fill = wash_fill\n",
    "\n",
    "                # Apply fill color to the corresponding cell\n",
    "                ws.cell(row=row_index + 2, column=len(row_data)).fill = fill\n",
    "            else:\n",
    "                # If there are no more sweeps for this folder, leave the cell empty\n",
    "                row_data.append('')\n",
    "\n",
    "        ws.append(row_data)\n",
    "\n",
    "    # Save the workbook\n",
    "    wb.save(output_path)\n",
    "    print(output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222ee0c-eacb-4252-bad8-1d6a182fabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze directory\n",
    "root_folder = '/mnt/team/Raymond Lab/Judy/iGluSnFR Experiments/0.5uM quinpirole/WT'\n",
    "process_directory(root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8cf6af-a956-4dd4-ac4e-d93412f91f5f",
   "metadata": {},
   "source": [
    "### Plotting the Area over time (Activation Volume)\n",
    "\n",
    "This section plots the activation volume for the average of last 6 sweeps of each condition (Baseline, Treatment, Wash) for each experiment, and saves them as 300dpi png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75bbe38e-35f6-4a83-bb2f-f1d4b85264d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# Helper function for natural sorting of file names\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# Plot function\n",
    "def plot_dff_stack_with_correct_transparency(sweep_stack, threshold, title, save_path):\n",
    "    frames, height, width = sweep_stack.shape\n",
    "    x = np.arange(width)\n",
    "    y = np.arange(height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Create the 3D plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Normalize the colormap to the desired range\n",
    "    norm = Normalize(vmin=0, vmax=0.2)\n",
    "\n",
    "    # Define z scaling to improve the spread of the plot in the Z-axis (time)\n",
    "    z_scale = 1  # Adjust this if the Z-axis looks squished\n",
    "\n",
    "    frame_step = 5  # Skipping frames to speed up (adjust based on your data size)\n",
    "    \n",
    "    for t in range(0, frames, frame_step):\n",
    "        frame = sweep_stack[t]\n",
    "\n",
    "        # Apply transparency: Create a facecolors array based on dF/F values and mask\n",
    "        facecolors = cm.jet(norm(frame))\n",
    "        \n",
    "        # Masking: Set alpha to 0 for values below the threshold (transparent), 0.6 for above, and 0.8 for way above, so that the core of the activated volume is clearly visible\n",
    "        below_threshold_mask = frame < threshold\n",
    "        above_threshold_mask = frame >= threshold\n",
    "        way_above_threshold_mask = frame >= 3*threshold\n",
    "        facecolors[below_threshold_mask, 3] = 0  # Set alpha channel to 0 where masked\n",
    "        facecolors[above_threshold_mask, 3] = 0.6\n",
    "        facecolors[way_above_threshold_mask, 3] = 0.8\n",
    "        \n",
    "        # Use plot_surface with custom facecolors\n",
    "        ax.plot_surface(X, np.ones((height, width)) * t * z_scale, Y,\n",
    "                        facecolors=facecolors, rstride=1, cstride=1, \n",
    "                        linewidth=0, antialiased=True)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_ylabel('Time (Frames)')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Adjust the Z-axis limit to make sure it looks well-proportioned\n",
    "    ax.set_ylim(0, frames * z_scale)\n",
    "\n",
    "    # Add color bar with the new limits (0 to 0.1)\n",
    "    mappable = cm.ScalarMappable(norm=norm, cmap='jet')\n",
    "    fig.colorbar(mappable, ax=ax, shrink=0.5, aspect=5, label=\"dF/F Value\")\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    \n",
    "    # Show the plot (optional, can be removed if you only want to save)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Main function to process the data and plot the average of last 6 dF/F sweeps\n",
    "def process_directory_with_dff_plot(root_folder):\n",
    "    # Go through each folder (root directories containing 'Baseline *', 'Treatment *', 'Wash *')\n",
    "    for folder in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        sub_dirs = ['Baseline', 'Treatment', 'Wash']\n",
    "        \n",
    "        # Process each subdirectory (Baseline, Treatment, Wash)\n",
    "        for sub_dir in sub_dirs:\n",
    "            matching_sub_dirs = [d for d in os.listdir(folder_path) if d.startswith(sub_dir)]\n",
    "            if not matching_sub_dirs:\n",
    "                continue\n",
    "\n",
    "            sub_dir_path = os.path.join(folder_path, matching_sub_dirs[0])\n",
    "\n",
    "            # Gather and sort hi, lo, and no tiff files using natural sorting\n",
    "            hi_files = sorted([f for f in os.listdir(sub_dir_path) if f.startswith('hi') and f.endswith('.tif')], key=natural_sort_key)\n",
    "            lo_files = sorted([f for f in os.listdir(sub_dir_path) if f.startswith('lo') and f.endswith('.tif')], key=natural_sort_key)\n",
    "            no_files = sorted([f for f in os.listdir(sub_dir_path) if f.startswith('no') and f.endswith('.tif')], key=natural_sort_key)\n",
    "\n",
    "            dff_values = []\n",
    "            for i, hi_file in enumerate(hi_files):\n",
    "                hi_stack = np.array(tiff.imread(os.path.join(sub_dir_path, hi_file)),dtype=np.float32)\n",
    "                no_stack = np.array(tiff.imread(os.path.join(sub_dir_path, no_files[i])),dtype=np.float32)\n",
    "                \n",
    "                if i < len(lo_files):\n",
    "                    lo_stack = np.array(tiff.imread(os.path.join(sub_dir_path, lo_files[i])),dtype=np.float32)\n",
    "                    dff_stack = (hi_stack - no_stack) / no_stack + (lo_stack - no_stack) / no_stack\n",
    "                    dff_stack /= 2  # Averaging the two dff calculations\n",
    "                    \n",
    "                else:\n",
    "                    dff_stack = (hi_stack - no_stack) / no_stack\n",
    "                    \n",
    "                dff_values.append(dff_stack)\n",
    "\n",
    "            # Calculate the average of the last 6 dF/F sweeps\n",
    "            avg_dff = np.mean(dff_values[-6:], axis=0)\n",
    "\n",
    "            # Calculate the threshold (4 times standard deviation of the first 30 frames)\n",
    "            std_dev = np.std(avg_dff[:30], axis=0)\n",
    "            threshold = 4 * std_dev\n",
    "\n",
    "            # Define the path to save the plot\n",
    "            plot_save_path = os.path.join(sub_dir_path, f\"{sub_dir}_average_dff_plot.png\")\n",
    "\n",
    "            # Plot the average dF/F stack and save it\n",
    "            plot_dff_stack_with_correct_transparency(avg_dff, threshold, f\"{sub_dir} Average dF/F Plot\", plot_save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45628f78-29c8-472d-85ed-e38c71422d07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the process function with the root folder path\n",
    "root_folder = '/mnt/team/Raymond Lab/Judy/dLight Experiments/WT/0.5uM quinpirole'\n",
    "process_directory_with_dff_plot(root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019bc811-0a0a-4869-9a3b-06767ef74ab9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Analysis of Stim-Response Experiments\n",
    "\n",
    "This section is for analysis of activated area following stimulations at different intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff4f54f-9c89-4c00-ad80-b452587681dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import pandas as pd\n",
    "\n",
    "# Helper function for natural sorting of file names\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# Function to calculate dF/F\n",
    "def calculate_dff(hi_stack, lo_stack, no_stack):\n",
    "    if lo_stack is not None:\n",
    "        dff_stack = (hi_stack - no_stack) / no_stack + (lo_stack - no_stack) / no_stack\n",
    "        dff_stack /= 2  # Averaging the two dff calculations\n",
    "    else:\n",
    "        dff_stack = (hi_stack - no_stack) / no_stack\n",
    "    return dff_stack\n",
    "\n",
    "# Function to calculate activation area based on dF/F thresholding\n",
    "def calculate_activation_area(dff_stack):\n",
    "    std_dev = np.std(dff_stack[:30], axis=0)\n",
    "    threshold = 4 * std_dev # Threshold set to 4 times standard dev of first 30 frames (as before)\n",
    "    activated_area = np.sum(dff_stack > threshold, axis=(1, 2))\n",
    "    total_activation_area = np.sum(activated_area)\n",
    "    return total_activation_area\n",
    "\n",
    "# Function to process the uA folder and calculate the average dF/F and activation area\n",
    "def process_uA_folder(uA_folder_path):\n",
    "    # Gather and sort hi, lo, and no tiff files using natural sorting\n",
    "    hi_files = sorted([f for f in os.listdir(uA_folder_path) if f.startswith('hi') and f.endswith('.tif')], key=natural_sort_key)\n",
    "    lo_files = sorted([f for f in os.listdir(uA_folder_path) if f.startswith('lo') and f.endswith('.tif')], key=natural_sort_key)\n",
    "    no_files = sorted([f for f in os.listdir(uA_folder_path) if f.startswith('no') and f.endswith('.tif')], key=natural_sort_key)\n",
    "\n",
    "    dff_values = []\n",
    "    for i, hi_file in enumerate(hi_files):\n",
    "        hi_stack = np.array(tiff.imread(os.path.join(uA_folder_path, hi_file)),dtype=np.float32)\n",
    "        no_stack = np.array(tiff.imread(os.path.join(uA_folder_path, no_files[i])),dtype=np.float32)\n",
    "\n",
    "        lo_stack = np.array(tiff.imread(os.path.join(uA_folder_path, lo_files[i])),dtype=np.float32) if i < len(lo_files) else None\n",
    "        dff_stack = calculate_dff(hi_stack, lo_stack, no_stack)\n",
    "        dff_values.append(dff_stack)\n",
    "\n",
    "    # Calculate the average of all dF/F stacks\n",
    "    avg_dff = np.mean(dff_values, axis=0)\n",
    "    \n",
    "    # Calculate activation area from the averaged dF/F\n",
    "    activation_area = calculate_activation_area(avg_dff)\n",
    "\n",
    "    return activation_area\n",
    "\n",
    "# Main function to process the root directory and generate the Excel sheet\n",
    "def process_root_directory(root_folder, output_excel_path):\n",
    "    # Define the fixed rows (uA values) for the Excel sheet\n",
    "    uA_folders = ['50uA', '60uA', '70uA', '80uA', '100uA', '200uA', '300uA', '400uA', '500uA']\n",
    "    \n",
    "    # Initialize the DataFrame for storing the results\n",
    "    results_df = pd.DataFrame(index=uA_folders)\n",
    "    \n",
    "    # Traverse the root folder\n",
    "    for dirpath, dirnames, _ in os.walk(root_folder):\n",
    "        # Check if the current directory contains uA folders\n",
    "        relevant_uA_folders = [d for d in dirnames if d.endswith('uA') and d in uA_folders]\n",
    "        if relevant_uA_folders:\n",
    "            folder_name = os.path.basename(dirpath)\n",
    "            print(folder_name)\n",
    "            folder_results = {}\n",
    "            \n",
    "            for uA_folder in relevant_uA_folders:\n",
    "                uA_folder_path = os.path.join(dirpath, uA_folder)\n",
    "                \n",
    "                # Process the uA folder and calculate activation area\n",
    "                activation_area = process_uA_folder(uA_folder_path)\n",
    "                \n",
    "                # Store the activation area in the folder results\n",
    "                folder_results[uA_folder] = activation_area\n",
    "            \n",
    "            # Add the results for this folder to the DataFrame\n",
    "            results_df[folder_name] = pd.Series(folder_results)\n",
    "\n",
    "    # Save the results to an Excel file\n",
    "    results_df.to_excel(output_excel_path)\n",
    "    print(output_excel_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdc026e3-f0c8-47e9-b81c-cbb2145aa3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023.08.11 (3)\n",
      "2023.06.29 (3)\n",
      "2023.06.29\n",
      "2023.06.28 (2)\n",
      "2023.06.29 (2)\n",
      "2023.08.16\n",
      "2023.08.11\n",
      "2023.08.11 (2)\n",
      "2023.08.16 (2)\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/WT_Area_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "root_folder = '/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT'\n",
    "output_excel_path = '/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/WT_Area_results.xlsx'\n",
    "\n",
    "# Process the directory and generate the Excel sheet\n",
    "process_root_directory(root_folder, output_excel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb349df-d214-40c8-99be-38eea9efdae3",
   "metadata": {},
   "source": [
    "### Plotting the results for the stim-response experiments\n",
    "\n",
    "This section creates the excel spreadsheets AND generates plots. Plot generation (due to the type of 3d Plots and the transparency modification is computationally expensive. Only run this part if you really need the plots as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc832147-e114-4276-85a6-30f7509cce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# Helper function for natural sorting of file names\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "# Function to calculate dF/F\n",
    "def calculate_dff(hi_stack, lo_stack, no_stack):\n",
    "    if lo_stack is not None:\n",
    "        dff_stack = (hi_stack - no_stack) / no_stack + (lo_stack - no_stack) / no_stack\n",
    "        dff_stack /= 2  # Averaging the two dff calculations\n",
    "    else:\n",
    "        dff_stack = (hi_stack - no_stack) / no_stack\n",
    "    return dff_stack\n",
    "\n",
    "# Function to calculate activation area based on dF/F thresholding\n",
    "def calculate_activation_area(dff_stack):\n",
    "    std_dev = np.std(dff_stack[:30], axis=0)\n",
    "    threshold = 4 * std_dev\n",
    "    activated_area = np.sum(dff_stack > threshold, axis=(1, 2))\n",
    "    total_activation_area = np.sum(activated_area)\n",
    "    return total_activation_area\n",
    "\n",
    "# 3D plot function for the averaged dF/F stack\n",
    "def plot_dff_stack_with_correct_transparency(sweep_stack, threshold, title, save_path):\n",
    "    frames, height, width = sweep_stack.shape\n",
    "    x = np.arange(width)\n",
    "    y = np.arange(height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # Create the 3D plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Normalize the colormap to the desired range (0 to 0.1)\n",
    "    norm = Normalize(vmin=0, vmax=0.1)\n",
    "\n",
    "    # Define z scaling to improve the spread of the plot in the Z-axis (time)\n",
    "    z_scale = 1  \n",
    "\n",
    "    frame_step = 5  # Skipping frames to speed up (adjust based on your data size)\n",
    "    for t in range(0, frames, frame_step):\n",
    "        frame = sweep_stack[t]\n",
    "\n",
    "        # Apply transparency: Create a facecolors array based on dF/F values and mask\n",
    "        facecolors = cm.jet(norm(frame))\n",
    "        \n",
    "        # Masking: Set alpha to 0 for values below the threshold (transparent)\n",
    "        below_threshold_mask = frame < threshold\n",
    "        above_threshold_mask = frame >= threshold\n",
    "        way_above_threshold_mask = frame >= 3*threshold\n",
    "        facecolors[below_threshold_mask, 3] = 0  # Set alpha channel to 0 where masked\n",
    "        facecolors[above_threshold_mask, 3] = 0.6\n",
    "        facecolors[way_above_threshold_mask, 3] = 0.9\n",
    "        # Use plot_surface with custom facecolors\n",
    "        ax.plot_surface(X, np.ones((height, width)) * t * z_scale, Y,\n",
    "                        facecolors=facecolors, rstride=1, cstride=1, \n",
    "                        linewidth=0, antialiased=True)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_ylabel('Time (Frames)')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # Adjust the Z-axis limit to make sure it looks well-proportioned\n",
    "    ax.set_ylim(0, frames * z_scale)\n",
    "\n",
    "    # Add color bar with the new limits \n",
    "    mappable = cm.ScalarMappable(norm=norm, cmap='jet')\n",
    "    fig.colorbar(mappable, ax=ax, shrink=0.5, aspect=5, label=\"dF/F Value\")\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(save_path)\n",
    "    # Show the plot (optional, can be removed if you only want to save)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Function to process the uA folder, calculate average dF/F and activation area, and plot 3D dF/F stack\n",
    "def process_uA_folder(uA_folder_path):\n",
    "    # Gather and sort hi, lo, and no tiff files using natural sorting\n",
    "    hi_files = sorted([f for f in os.listdir(uA_folder_path) if f.startswith('hi') and f.endswith('.tif')], key=natural_sort_key)\n",
    "    lo_files = sorted([f for f in os.listdir(uA_folder_path) if f.startswith('lo') and f.endswith('.tif')], key=natural_sort_key)\n",
    "    no_files = sorted([f for f in os.listdir(uA_folder_path) if f.startswith('no') and f.endswith('.tif')], key=natural_sort_key)\n",
    "\n",
    "    dff_values = []\n",
    "    for i, hi_file in enumerate(hi_files):\n",
    "        hi_stack = np.array(tiff.imread(os.path.join(uA_folder_path, hi_file)),dtype=np.float32)\n",
    "        no_stack = np.array(tiff.imread(os.path.join(uA_folder_path, no_files[i])),dtype=np.float32)\n",
    "\n",
    "        lo_stack = np.array(tiff.imread(os.path.join(uA_folder_path, lo_files[i])),dtype=np.float32) if i < len(lo_files) else None\n",
    "        dff_stack = calculate_dff(hi_stack, lo_stack, no_stack)\n",
    "        dff_values.append(dff_stack)\n",
    "\n",
    "    # Calculate the average of all dF/F stacks\n",
    "    avg_dff = np.mean(dff_values, axis=0)\n",
    "    \n",
    "    # Calculate activation area from the averaged dF/F\n",
    "    activation_area = calculate_activation_area(avg_dff)\n",
    "\n",
    "    # Plot and save the 3D plot of the average dF/F\n",
    "    std_dev = np.std(avg_dff[:30], axis=0)\n",
    "    threshold = 4 * std_dev\n",
    "    plot_save_path = os.path.join(os.path.dirname(uA_folder_path),\"plots\", f\"{os.path.basename(uA_folder_path)}_average_dff_plot.png\")\n",
    "    plot_dff_stack_with_correct_transparency(avg_dff, threshold, f\"{uA_folder_path} Average dF/F Plot\", plot_save_path)\n",
    "\n",
    "    return activation_area\n",
    "\n",
    "# Main function to process the root directory, plot dF/F and generate the Excel sheet\n",
    "def process_root_directory_with_plots(root_folder, output_excel_path):\n",
    "    # Define the fixed rows (uA values) for the Excel sheet\n",
    "    uA_folders = ['50uA', '60uA', '70uA', '80uA', '100uA', '200uA', '300uA', '400uA', '500uA']\n",
    "    \n",
    "    # Initialize the DataFrame for storing the results\n",
    "    results_df = pd.DataFrame(index=uA_folders)\n",
    "    \n",
    "    # Traverse the root folder\n",
    "    for dirpath, dirnames, _ in os.walk(root_folder):\n",
    "        # Check if the current directory contains uA folders\n",
    "        relevant_uA_folders = [d for d in dirnames if d.endswith('uA') and d in uA_folders]\n",
    "        if relevant_uA_folders:\n",
    "            folder_name = os.path.basename(dirpath)\n",
    "            folder_results = {}\n",
    "            \n",
    "            for uA_folder in relevant_uA_folders:\n",
    "                uA_folder_path = os.path.join(dirpath, uA_folder)\n",
    "                \n",
    "                # Process the uA folder, calculate activation area and generate plot\n",
    "                activation_area = process_uA_folder(uA_folder_path)\n",
    "                \n",
    "                # Store the activation area in the folder results\n",
    "                folder_results[uA_folder] = activation_area\n",
    "            \n",
    "            # Add the results for this folder to the DataFrame\n",
    "            results_df[folder_name] = pd.Series(folder_results)\n",
    "\n",
    "    # Save the results to an Excel file\n",
    "    results_df.to_excel(output_excel_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e309549-2759-4a35-8eef-60552da8f2b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (3)/plots/70uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (3)/plots/60uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (3)/plots/80uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (3)/plots/400uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (3)/plots/300uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (3)/plots/100uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (3)/plots/50uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (3)/plots/200uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (3)/plots/500uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.29 (3)/plots/400uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.29 (3)/plots/300uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.29 (3)/plots/500uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.29/plots/400uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.29/plots/300uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.29/plots/500uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.28 (2)/plots/400uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.28 (2)/plots/300uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.28 (2)/plots/500uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.29 (2)/plots/400uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.29 (2)/plots/300uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.06.29 (2)/plots/500uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16/plots/400uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16/plots/100uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16/plots/50uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16/plots/200uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11/plots/70uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11/plots/60uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11/plots/80uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11/plots/400uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11/plots/300uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11/plots/100uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11/plots/50uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11/plots/200uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11/plots/500uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (2)/plots/70uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (2)/plots/60uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (2)/plots/80uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (2)/plots/400uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (2)/plots/300uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (2)/plots/100uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (2)/plots/50uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (2)/plots/200uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.11 (2)/plots/500uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16 (2)/plots/70uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16 (2)/plots/60uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16 (2)/plots/80uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16 (2)/plots/400uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16 (2)/plots/300uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16 (2)/plots/100uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16 (2)/plots/50uA_average_dff_plot.png\n",
      "/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/2023.08.16 (2)/plots/500uA_average_dff_plot.png\n"
     ]
    }
   ],
   "source": [
    "root_folder = '/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT'\n",
    "output_excel_path = '/mnt/team/Raymond Lab/Judy/dLight Experiments/Stim-Response Curves/WT/test.xlsx'\n",
    "\n",
    "# Process the directory, generate plots and the Excel sheet\n",
    "process_root_directory_with_plots(root_folder, output_excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf055133-cdaa-4b60-9a7f-e8146a58dd5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
